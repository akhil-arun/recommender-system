{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "/Users/harshadakumbhare/Documents/GitHub/akshaydaf/recommender-system\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys\n",
    "# compute the absolute path to your project root:\n",
    "root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "print(root)\n",
    "# insert it at the front of Python’s module search path:\n",
    "sys.path.insert(0, root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1444/1444 [01:32<00:00, 15.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Loss: 77.8458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from models.sequential_dcn_v2 import DCNV2_Sequential\n",
    "from models.vanilla_nn import TwoLayerNet\n",
    "from trainer import Trainer\n",
    "from data_utils.datasets import CustomDataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import argparse\n",
    "import yaml\n",
    "from config import Config\n",
    "import pandas as pd\n",
    "\n",
    "# parser = argparse.ArgumentParser(description=\"trainer\")\n",
    "# parser.add_argument('--config_file', type=str, default='configs/config_nn.yaml', help=\"path to YAML config\")\n",
    "# parser.add_argument('--output_dir', type=str, default=None,\n",
    "#                     help=\"path to output directory (optional); defaults to outputs/model_name\")\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# config_file = \"configs/config_dcn_v2_sequential.yaml\"\n",
    "config_file = \"/Users/harshadakumbhare/Documents/GitHub/akshaydaf/recommender-system/configs/config_dcn_v2_sequential.yaml\"\n",
    "# datapath = 'data/dataset.csv'\n",
    "datapath = '/Users/harshadakumbhare/Documents/GitHub/akshaydaf/recommender-system/data/dataset.csv'\n",
    "\n",
    "with open(config_file, 'r') as file:\n",
    "    config_dict = yaml.safe_load(file)\n",
    "    config = Config(config_dict=config_dict)\n",
    "df = pd.read_csv(datapath)\n",
    "target_column = 'rating'\n",
    "\n",
    "if config.network.model == 'nn':\n",
    "    # Generate sparse input.\n",
    "    X_sparse_input = {}\n",
    "\n",
    "    # Generate dense input.\n",
    "    X_dense_columns = list(set(df.columns)- {target_column})\n",
    "    X_dense_input = torch.tensor(df[X_dense_columns].values, dtype=torch.float32)\n",
    "    y = torch.tensor(df[target_column].values, dtype=torch.float32)\n",
    "elif config.network.model == 'dcn_v2_sequential':\n",
    "    # Generate sparse input.\n",
    "    sparse_feature_info = {\n",
    "        # name: (vocab_size, embed_size)\n",
    "        \"uid\": (10000, 64),       # 10,000 users, 64-dim embedding\n",
    "        \"movie_id\": (5000, 64),        # 5,000 items, 64-dim embedding\n",
    "        # \"age_sparse\": (7, 8),        # 5,000 items, 64-dim embedding\n",
    "    }\n",
    "    sparse_columns = sparse_feature_info.keys()\n",
    "    X_sparse_input = {\n",
    "        name: torch.tensor(df[name])\n",
    "        for name, (vocab_size, embed_size) in sparse_feature_info.items()\n",
    "    }\n",
    "\n",
    "    # Generate dense input.\n",
    "    dense_columns = list(set(df.columns) - set(sparse_columns) - {target_column})\n",
    "    num_dense_features = len(dense_columns)\n",
    "    X_dense_input = torch.tensor(df[dense_columns].values)\n",
    "    y = torch.tensor(df[target_column].values, dtype=torch.float32)\n",
    "\n",
    "dataset = CustomDataset(X_sparse_input, X_dense_input, y)\n",
    "loader = DataLoader(dataset, batch_size=config.train.batch_size, shuffle=True)\n",
    "\n",
    "if config.network.model == 'nn':\n",
    "    model = TwoLayerNet(input_dim=len(X_dense_columns), hidden_size=784, num_classes=1)\n",
    "elif config.network.model == 'dcn_parallel':\n",
    "    model = TwoLayerNet(input_dim=len(X_dense_columns), hidden_size=784, num_classes=1)\n",
    "elif config.network.model == 'dcn_v2_sequential':\n",
    "    model = DCNV2_Sequential(sparse_feature_info=sparse_feature_info, num_dense_features=num_dense_features)\n",
    "\n",
    "trainer = Trainer(model, None, config, loader, float(config.train.lr))\n",
    "\n",
    "trainer.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cpu\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "evaluate_DCNV2Model() got an unexpected keyword argument 'df'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# 3) global item set\u001b[39;00m\n\u001b[1;32m     29\u001b[0m all_movies \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(movies[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMovieID\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m---> 31\u001b[0m \u001b[43mevaluate_DCNV2Model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_splits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_items\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_movies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: evaluate_DCNV2Model() got an unexpected keyword argument 'df'"
     ]
    }
   ],
   "source": [
    "# Evaluate Model\n",
    "\n",
    "\n",
    "\n",
    "from data_utils.preprocess import (\n",
    "    load_movielens, clean_and_filter,\n",
    "    get_user_sequences, split_sequences,\n",
    "    build_examples, pad_sequences,\n",
    "    build_user_table, build_movie_table\n",
    ")\n",
    "\n",
    "from evaluation import evaluate_ranking_model, evaluate_DCNV2Model, evaluate_featureaware_model\n",
    "\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "print(\"Running on\", device)\n",
    "\n",
    "data_dir = \"../data\"\n",
    "# 1) load & filter\n",
    "ratings, users, movies = load_movielens(data_dir)\n",
    "ratings, users, movies = clean_and_filter(ratings, users, movies, rating_threshold=4)\n",
    "\n",
    "# 2) build per-user sequences & splits\n",
    "user_seqs   = get_user_sequences(ratings)\n",
    "user_splits = split_sequences(user_seqs, train_ratio=0.8, val_ratio=0.1)\n",
    "\n",
    "\n",
    "\n",
    "# 3) global item set\n",
    "all_movies = set(movies[\"MovieID\"].unique())\n",
    "\n",
    "evaluate_DCNV2Model(model=model, user_splits=user_splits, global_items=all_movies, device=device, df=df) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
